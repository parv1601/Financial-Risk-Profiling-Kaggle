{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing and Loading data"
      ],
      "metadata": {
        "id": "hfjKxpMkXOvR"
      },
      "id": "hfjKxpMkXOvR"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam, schedules\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "import warnings\n",
        "\n",
        "# Suppress ConvergenceWarning from LinearSVC for cleaner output\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "# --- 1. Load Data and Prepare X and y (Training) ---\n",
        "df_train = pd.read_csv(\"train_processed_parv.csv\")\n",
        "bool_cols_train = df_train.select_dtypes(include='bool').columns\n",
        "df_train[bool_cols_train] = df_train[bool_cols_train].astype(int)\n",
        "\n",
        "X = df_train.drop(columns=['ProfileID', 'RiskFlag'])\n",
        "y = df_train['RiskFlag']\n",
        "\n",
        "# Split for full training (80%) and evaluation (20%)\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Create the 20% Training Sample (25% of X_train_full = 20% of original data)\n",
        "X_train_20pct, X_temp, y_train_20pct, y_temp = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=0.75, random_state=42, stratify=y_train_full\n",
        ")\n",
        "\n",
        "input_dim = X_train_full.shape[1]\n",
        "\n",
        "print(f\"Total Features: {input_dim}\")\n",
        "print(f\"20% Training Sample Size: {len(X_train_20pct)}\")\n",
        "print(f\"Full Training Set Size: {len(X_train_full)}\")\n",
        "print(f\"Evaluation Test Set Size: {len(X_test)}\\n\")\n",
        "\n",
        "# --- 2. Load and Prepare X for Submission (Competition Test Data) ---\n",
        "df_test = pd.read_csv(\"test_processed_parv.csv\")\n",
        "bool_cols_test = df_test.select_dtypes(include='bool').columns\n",
        "df_test[bool_cols_test] = df_test[bool_cols_test].astype(int)\n",
        "\n",
        "# X_submit is the actual competition test data to predict\n",
        "X_submit = df_test.drop(columns=['ProfileID'])\n",
        "profile_ids = df_test['ProfileID']\n",
        "print(f\"Submission Test Set Size: {len(X_submit)}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jzk9V2FKO8O_",
        "outputId": "04ab4e6d-edf2-4296-dd43-cff79ffc266a"
      },
      "id": "Jzk9V2FKO8O_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Features: 26\n",
            "20% Training Sample Size: 40855\n",
            "Full Training Set Size: 163421\n",
            "Evaluation Test Set Size: 40856\n",
            "\n",
            "Submission Test Set Size: 51070\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Common Functions and Neural Networks"
      ],
      "metadata": {
        "id": "bT1GtcmTO-wk"
      },
      "id": "bT1GtcmTO-wk"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Define Common Functions ---\n",
        "\n",
        "def evaluate_model(model_name, model, X_train, y_train, X_eval, y_eval, is_ann=False):\n",
        "    \"\"\"Trains, predicts, and reports metrics for a given model.\"\"\"\n",
        "    print(f\"--- Training {model_name} on {len(X_train)} samples... ---\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    if is_ann:\n",
        "        model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "    print(f\"Training Time: {training_time:.2f} seconds\")\n",
        "\n",
        "    # Predict on the hold-out evaluation set\n",
        "    if is_ann:\n",
        "        y_pred_proba = model.predict(X_eval, verbose=0)\n",
        "        y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
        "    else:\n",
        "        y_pred = model.predict(X_eval)\n",
        "\n",
        "    accuracy = accuracy_score(y_eval, y_pred)\n",
        "    auc = roc_auc_score(y_eval, y_pred)\n",
        "\n",
        "    print(f\"Evaluation Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Evaluation ROC AUC: {auc:.4f}\")\n",
        "    print(\"\\nClassification Report (on Evaluation Set):\")\n",
        "    print(classification_report(y_eval, y_pred, zero_division=0))\n",
        "    print(\"-\" * 50)\n",
        "    return model # Return the trained model\n",
        "\n",
        "def create_ann_model(input_dim):\n",
        "    \"\"\"Creates a basic ANN model for binary classification.\"\"\"\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_shape=(input_dim,)),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "wTVkAcWnPChr"
      },
      "id": "wTVkAcWnPChr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear SVM"
      ],
      "metadata": {
        "id": "CjaWAVcQPQMX"
      },
      "id": "CjaWAVcQPQMX"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- A. Linear SVM (Training on 20% Sample) ---\n",
        "\n",
        "linear_svm_20pct = LinearSVC(random_state=42, dual=True, max_iter=10000)\n",
        "\n",
        "evaluate_model(\"Linear SVM (20%)\", linear_svm_20pct,\n",
        "\n",
        "X_train_20pct, y_train_20pct, X_test, y_test)\n",
        "\n",
        "\n",
        "\n",
        "# --- B. Linear SVM (Training on Full Dataset) ---\n",
        "\n",
        "final_linear_svm = LinearSVC(random_state=42, dual=True, max_iter=10000)\n",
        "\n",
        "final_linear_svm = evaluate_model(\"Linear SVM (Full)\", final_linear_svm,\n",
        "\n",
        "X_train_full, y_train_full, X_test, y_test)\n",
        "\n",
        "# Suppress warnings that may arise from L1 penalty/loss combinations during CV\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# --- 1. Define Model for Tuning ---\n",
        "# Use the same base model with high max_iter\n",
        "model_linear_svm = LinearSVC(random_state=42, dual=True, max_iter=10000)\n",
        "\n",
        "# --- 2. Define the CORRECTED Grid ---\n",
        "# We eliminate the unsupported l1/hinge combinations.\n",
        "# We will focus on the L2 penalty which is robust and works well with dual=True.\n",
        "param_grid_linear_svm = {\n",
        "    'C': [0.1, 1.0, 10.0],\n",
        "    'penalty': ['l2'], # Only use L2 penalty for robust/fast results with dual=True\n",
        "    'loss': ['hinge', 'squared_hinge']\n",
        "}\n",
        "# Total Candidates: 3 * 1 * 2 = 6 candidates. (Reduced from 12, greatly reducing runtime and error chance)\n",
        "\n",
        "# Initialize GridSearchCV (using ROC AUC)\n",
        "grid_search_linear_svm = GridSearchCV(\n",
        "    estimator=model_linear_svm,\n",
        "    param_grid=param_grid_linear_svm,\n",
        "    scoring='roc_auc',\n",
        "    cv=3,\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"\\n--- Starting Hyperparameter Tuning for Linear SVM (Corrected Grid) ---\")\n",
        "grid_search_linear_svm.fit(X_train_full, y_train_full)\n",
        "\n",
        "# Get the best estimator and parameters\n",
        "best_linear_svm = grid_search_linear_svm.best_estimator_\n",
        "print(\"\\n--- TUNING RESULTS (Linear SVM) ---\")\n",
        "print(f\"Best ROC AUC score found: {grid_search_linear_svm.best_score_:.4f}\")\n",
        "print(f\"Best parameters: {grid_search_linear_svm.best_params_}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Evaluate the final, best model on the holdout test set\n",
        "final_linear_svm_tuned = evaluate_model(\"Tuned Linear SVM (Full)\", best_linear_svm,\n",
        "                                  X_train_full, y_train_full, X_test, y_test)\n",
        "\n",
        "\n",
        "# --- Prediction and Submission (Using the Tuned Model) ---\n",
        "print(\"Predicting with Tuned Linear SVM (Full) on Test Data...\")\n",
        "y_pred_linear = final_linear_svm_tuned.predict(X_submit)\n",
        "\n",
        "# Create and save the submission DataFrame\n",
        "submission_df_linear = pd.DataFrame({\n",
        "    'ProfileID': profile_ids,\n",
        "    'RiskFlag': y_pred_linear\n",
        "})\n",
        "submission_filename_linear = 'submission_linear_svm_tuned.csv'\n",
        "submission_df_linear.to_csv(submission_filename_linear, index=False)\n",
        "print(f\"Generated submission file: {submission_filename_linear}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPRZFSeNPR_F",
        "outputId": "1cfafc25-4cbb-45e5-e342-c822e74be33f"
      },
      "id": "bPRZFSeNPR_F",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Training Linear SVM (20%) on 40855 samples... ---\n",
            "Training Time: 10.30 seconds\n",
            "Evaluation Accuracy: 0.8837\n",
            "Evaluation ROC AUC: 0.5002\n",
            "\n",
            "Classification Report (on Evaluation Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.94     36105\n",
            "           1       0.50      0.00      0.00      4751\n",
            "\n",
            "    accuracy                           0.88     40856\n",
            "   macro avg       0.69      0.50      0.47     40856\n",
            "weighted avg       0.84      0.88      0.83     40856\n",
            "\n",
            "--------------------------------------------------\n",
            "--- Training Linear SVM (Full) on 163421 samples... ---\n",
            "Training Time: 74.21 seconds\n",
            "Evaluation Accuracy: 0.8837\n",
            "Evaluation ROC AUC: 0.5002\n",
            "\n",
            "Classification Report (on Evaluation Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.94     36105\n",
            "           1       0.67      0.00      0.00      4751\n",
            "\n",
            "    accuracy                           0.88     40856\n",
            "   macro avg       0.78      0.50      0.47     40856\n",
            "weighted avg       0.86      0.88      0.83     40856\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Starting Hyperparameter Tuning for Linear SVM (Corrected Grid) ---\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting and Testing Linear SVM"
      ],
      "metadata": {
        "id": "NYr4d_2scqqA"
      },
      "id": "NYr4d_2scqqA"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Prediction and Submission (Using the Tuned Model) ---\n",
        "print(\"Predicting with Tuned Linear SVM (Full) on Test Data...\")\n",
        "y_pred_linear = final_linear_svm_tuned.predict(X_submit)\n",
        "\n",
        "# Create and save the submission DataFrame\n",
        "submission_df_linear = pd.DataFrame({\n",
        "    'ProfileID': profile_ids,\n",
        "    'RiskFlag': y_pred_linear\n",
        "})\n",
        "submission_filename_linear = 'submission_linear_svm_tuned.csv'\n",
        "submission_df_linear.to_csv(submission_filename_linear, index=False)"
      ],
      "metadata": {
        "id": "DcXyFFP-cuT8"
      },
      "id": "DcXyFFP-cuT8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kernalized SVM"
      ],
      "metadata": {
        "id": "MrCAv7LSPVFU"
      },
      "id": "MrCAv7LSPVFU"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- A. Kernelized SVM (RBF) (Training on 20% Sample) ---\n",
        "# NOW TRAINING ON THE ENTIRE 20% SAMPLE (X_train_20pct)\n",
        "rbf_svm_20pct = SVC(kernel='rbf', gamma='scale', random_state=42)\n",
        "rbf_svm_20pct = evaluate_model(\"Kernelized SVM (RBF) (20% full sample)\", rbf_svm_20pct,\n",
        "               X_train_20pct, y_train_20pct, X_test, y_test)\n",
        "\n",
        "\n",
        "# --- B. Kernelized SVM (RBF) (Training on Full Dataset) ---\n",
        "# NOW TRAINING ON THE ENTIRE FULL TRAINING DATASET (X_train_full)\n",
        "final_rbf_svm = SVC(kernel='rbf', gamma='scale', random_state=42)\n",
        "final_rbf_svm = evaluate_model(\"Kernelized SVM (RBF) (Full Dataset)\", final_rbf_svm,\n",
        "                               X_train_full, y_train_full, X_test, y_test)\n",
        "\n",
        "# Define the model\n",
        "model_rbf_svm = SVC(random_state=42, kernel='rbf', probability=True) # probability=True needed for roc_auc scoring\n",
        "\n",
        "# Define a small, feasible grid of parameters to search due to high complexity\n",
        "param_grid_rbf_svm = {\n",
        "    'C': [1.0, 5.0],\n",
        "    'gamma': ['scale', 0.1]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV (using ROC AUC)\n",
        "print(\"--- WARNING: Kernelized SVM Tuning is highly time-consuming! ---\")\n",
        "grid_search_rbf_svm = GridSearchCV(\n",
        "    estimator=model_rbf_svm,\n",
        "    param_grid=param_grid_rbf_svm,\n",
        "    scoring='roc_auc',\n",
        "    cv=3,\n",
        "    verbose=2,\n",
        "    n_jobs=-1 # Use all available cores\n",
        ")\n",
        "\n",
        "print(\"\\n--- Starting Hyperparameter Tuning for Kernelized SVM ---\")\n",
        "grid_search_rbf_svm.fit(X_train_full, y_train_full)\n",
        "\n",
        "# Get the best estimator and parameters\n",
        "best_rbf_svm = grid_search_rbf_svm.best_estimator_\n",
        "print(\"\\n--- TUNING RESULTS (Kernelized SVM) ---\")\n",
        "print(f\"Best ROC AUC score found: {grid_search_rbf_svm.best_score_:.4f}\")\n",
        "print(f\"Best parameters: {grid_search_rbf_svm.best_params_}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Evaluate the final, best model on the holdout test set\n",
        "final_rbf_svm = evaluate_model(\"Tuned Kernelized SVM (Full)\", best_rbf_svm,\n",
        "                               X_train_full, y_train_full, X_test, y_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "wJlAIvbqPZG5"
      },
      "id": "wJlAIvbqPZG5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting and Testing Kernelized SVM"
      ],
      "metadata": {
        "id": "ziBIExNkc0jy"
      },
      "id": "ziBIExNkc0jy"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- C. Prediction and Submission ---\n",
        "print(\"Predicting with Kernelized SVM (Full Dataset) on Test Data...\")\n",
        "y_pred_rbf = final_rbf_svm.predict(X_submit)\n",
        "\n",
        "# Create and save the submission DataFrame\n",
        "submission_df_rbf = pd.DataFrame({\n",
        "    'ProfileID': profile_ids,\n",
        "    'RiskFlag': y_pred_rbf\n",
        "})\n",
        "submission_filename_rbf = 'submission_kernelized_svm.csv'\n",
        "submission_df_rbf.to_csv(submission_filename_rbf, index=False)\n",
        "print(f\"Generated submission file: {submission_filename_rbf}\")"
      ],
      "metadata": {
        "id": "biS859s3c3xD"
      },
      "id": "biS859s3c3xD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP (Neural Networks)"
      ],
      "metadata": {
        "id": "a0zXA3dLPeuF"
      },
      "id": "a0zXA3dLPeuF"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Helper function to create a Keras model (slightly modified for standalone use)\n",
        "def create_model_manual(input_dim, neurons, learning_rate):\n",
        "    model = Sequential([\n",
        "        Dense(neurons, activation='relu', input_shape=(input_dim,)),\n",
        "        Dense(int(neurons / 2), activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Define the grid of parameters to search (8 candidates)\n",
        "tuning_grid = [\n",
        "    {'neurons': 32, 'learning_rate': 0.001, 'batch_size': 32},\n",
        "    {'neurons': 64, 'learning_rate': 0.001, 'batch_size': 32},\n",
        "    {'neurons': 32, 'learning_rate': 0.01, 'batch_size': 32},\n",
        "    {'neurons': 64, 'learning_rate': 0.01, 'batch_size': 64},\n",
        "    {'neurons': 32, 'learning_rate': 0.001, 'batch_size': 64},\n",
        "    {'neurons': 64, 'learning_rate': 0.001, 'batch_size': 64},\n",
        "    {'neurons': 32, 'learning_rate': 0.01, 'batch_size': 64},\n",
        "    {'neurons': 64, 'learning_rate': 0.01, 'batch_size': 32}\n",
        "]\n",
        "\n",
        "# Initialize KFold for Cross-Validation (CV)\n",
        "kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "best_auc = -1\n",
        "best_params = {}\n",
        "input_dim = X_train_full.shape[1]\n",
        "epochs = 5 # Use 5 epochs for faster CV\n",
        "\n",
        "print(f\"--- Starting Manual 3-Fold Tuning for MLP ({len(tuning_grid)} Candidates) ---\")\n",
        "\n",
        "# Iterate through every parameter combination\n",
        "for params in tuning_grid:\n",
        "    cv_auc_scores = []\n",
        "\n",
        "    # Perform 3-Fold Cross-Validation\n",
        "    for train_index, val_index in kfold.split(X_train_full, y_train_full):\n",
        "        X_train_fold, X_val_fold = X_train_full.iloc[train_index], X_train_full.iloc[val_index]\n",
        "        y_train_fold, y_val_fold = y_train_full.iloc[train_index], y_train_full.iloc[val_index]\n",
        "\n",
        "        # 1. Create and compile model\n",
        "        model = create_model_manual(input_dim, params['neurons'], params['learning_rate'])\n",
        "\n",
        "        # 2. Train model\n",
        "        model.fit(X_train_fold, y_train_fold,\n",
        "                  epochs=epochs,\n",
        "                  batch_size=params['batch_size'],\n",
        "                  verbose=0)\n",
        "\n",
        "        # 3. Predict probabilities and calculate ROC AUC\n",
        "        y_pred_proba = model.predict(X_val_fold, verbose=0).flatten()\n",
        "        fold_auc = roc_auc_score(y_val_fold, y_pred_proba)\n",
        "        cv_auc_scores.append(fold_auc)\n",
        "\n",
        "    # Calculate average AUC for this parameter set\n",
        "    mean_auc = np.mean(cv_auc_scores)\n",
        "\n",
        "    print(f\"Candidate {params} | Avg CV ROC AUC: {mean_auc:.4f}\")\n",
        "\n",
        "    # Check for the best parameter combination\n",
        "    if mean_auc > best_auc:\n",
        "        best_auc = mean_auc\n",
        "        best_params = params\n",
        "\n",
        "print(\"\\n--- TUNING RESULTS (MLP/ANN) ---\")\n",
        "print(f\"Best ROC AUC score found: {best_auc:.4f}\")\n",
        "print(f\"Best parameters: {best_params}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "\n",
        "# --- Retrain FINAL Model with Best Parameters and Full Epochs ---\n",
        "\n",
        "# 1. Create the final model using best parameters\n",
        "final_mlp_model = create_model_manual(\n",
        "    input_dim=input_dim,\n",
        "    neurons=best_params['neurons'],\n",
        "    learning_rate=best_params['learning_rate']\n",
        ")\n",
        "\n",
        "# 2. Use the original evaluate_model function to train and report (e.g., using 10 epochs)\n",
        "# NOTE: The evaluate_model function must be called with the appropriate arguments.\n",
        "# Since we are outside the GridSearch environment, we call the fit method directly.\n",
        "final_mlp_model.fit(X_train_full, y_train_full,\n",
        "                    epochs=10,\n",
        "                    batch_size=best_params['batch_size'],\n",
        "                    verbose=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--iKzZ1-PhD7",
        "outputId": "c99aa5d8-933c-40d0-bbb1-bc1c752522df"
      },
      "id": "--iKzZ1-PhD7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Manual 3-Fold Tuning for MLP (8 Candidates) ---\n",
            "Candidate {'neurons': 32, 'learning_rate': 0.001, 'batch_size': 32} | Avg CV ROC AUC: 0.7489\n",
            "Candidate {'neurons': 64, 'learning_rate': 0.001, 'batch_size': 32} | Avg CV ROC AUC: 0.7498\n",
            "Candidate {'neurons': 32, 'learning_rate': 0.01, 'batch_size': 32} | Avg CV ROC AUC: 0.7511\n",
            "Candidate {'neurons': 64, 'learning_rate': 0.01, 'batch_size': 64} | Avg CV ROC AUC: 0.7501\n",
            "Candidate {'neurons': 32, 'learning_rate': 0.001, 'batch_size': 64} | Avg CV ROC AUC: 0.7495\n",
            "Candidate {'neurons': 64, 'learning_rate': 0.001, 'batch_size': 64} | Avg CV ROC AUC: 0.7497\n",
            "Candidate {'neurons': 32, 'learning_rate': 0.01, 'batch_size': 64} | Avg CV ROC AUC: 0.7509\n",
            "Candidate {'neurons': 64, 'learning_rate': 0.01, 'batch_size': 32} | Avg CV ROC AUC: 0.7497\n",
            "\n",
            "--- TUNING RESULTS (MLP/ANN) ---\n",
            "Best ROC AUC score found: 0.7511\n",
            "Best parameters: {'neurons': 32, 'learning_rate': 0.01, 'batch_size': 32}\n",
            "--------------------------------------------------\n",
            "\n",
            "--- FINAL EVALUATION of Tuned MLP (Full, 10 Epochs) ---\n",
            "Evaluation Accuracy: 0.8853\n",
            "Evaluation ROC AUC: 0.7546\n",
            "\n",
            "Classification Report (on Evaluation Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.99      0.94     36105\n",
            "           1       0.56      0.06      0.11      4751\n",
            "\n",
            "    accuracy                           0.89     40856\n",
            "   macro avg       0.73      0.53      0.53     40856\n",
            "weighted avg       0.85      0.89      0.84     40856\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting and Testing Neural Networks"
      ],
      "metadata": {
        "id": "Y0RNXG4Ec83u"
      },
      "id": "Y0RNXG4Ec83u"
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Evaluate the final, best model on the holdout test set (X_test, y_test)\n",
        "print(\"\\n--- FINAL EVALUATION of Tuned MLP (Full, 10 Epochs) ---\")\n",
        "y_pred_proba_final = final_mlp_model.predict(X_test, verbose=0).flatten()\n",
        "y_pred_final = (y_pred_proba_final > 0.5).astype(int)\n",
        "\n",
        "final_accuracy = accuracy_score(y_test, y_pred_final)\n",
        "final_auc = roc_auc_score(y_test, y_pred_proba_final)\n",
        "\n",
        "print(f\"Evaluation Accuracy: {final_accuracy:.4f}\")\n",
        "print(f\"Evaluation ROC AUC: {final_auc:.4f}\")\n",
        "print(\"\\nClassification Report (on Evaluation Set):\")\n",
        "print(classification_report(y_test, y_pred_final, zero_division=0))"
      ],
      "metadata": {
        "id": "Xi3EtJ0uc_9k"
      },
      "id": "Xi3EtJ0uc_9k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "gg5gtCMDWYgQ"
      },
      "id": "gg5gtCMDWYgQ"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# --- A. Logistic Regression (Training on 20% Sample) ---\n",
        "# Use max_iter=1000 for convergence on large datasets\n",
        "log_reg_20pct = LogisticRegression(random_state=42, solver='liblinear', max_iter=1000)\n",
        "\n",
        "# Define the grid of parameters to search\n",
        "param_grid_log_reg = {\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'C': [0.1, 1.0, 10.0],\n",
        "    'solver': ['liblinear'] # liblinear supports both l1 and l2\n",
        "}\n",
        "\n",
        "evaluate_model(\"Logistic Regression (20%)\", log_reg_20pct,\n",
        "               X_train_20pct, y_train_20pct, X_test, y_test)\n",
        "\n",
        "# --- B. Logistic Regression (Training on Full Dataset) ---\n",
        "final_log_reg = LogisticRegression(random_state=42, solver='liblinear', max_iter=1000)\n",
        "final_log_reg = evaluate_model(\"Logistic Regression (Full)\", final_log_reg,\n",
        "                               X_train_full, y_train_full, X_test, y_test)\n",
        "\n",
        "# Define the model\n",
        "model_log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
        "\n",
        "# Initialize GridSearchCV (using ROC AUC as the primary metric)\n",
        "grid_search_log_reg = GridSearchCV(\n",
        "    estimator=model_log_reg,\n",
        "    param_grid=param_grid_log_reg,\n",
        "    scoring='roc_auc',\n",
        "    cv=3, # Use 3-fold cross-validation\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"--- Starting Hyperparameter Tuning for Logistic Regression ---\")\n",
        "grid_search_log_reg.fit(X_train_full, y_train_full)\n",
        "\n",
        "# Get the best estimator and parameters\n",
        "best_log_reg = grid_search_log_reg.best_estimator_\n",
        "print(\"\\n--- TUNING RESULTS (Logistic Regression) ---\")\n",
        "print(f\"Best ROC AUC score found: {grid_search_log_reg.best_score_:.4f}\")\n",
        "print(f\"Best parameters: {grid_search_log_reg.best_params_}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Evaluate the final, best model on the holdout test set\n",
        "final_log_reg = evaluate_model(\"Tuned Logistic Regression (Full)\", best_log_reg,\n",
        "                               X_train_full, y_train_full, X_test, y_test)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cr0lSYyNWbEd",
        "outputId": "3ce046b1-bab6-49a9-dcc2-c8f4e2933335"
      },
      "id": "cr0lSYyNWbEd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Training Logistic Regression (20%) on 40855 samples... ---\n",
            "Training Time: 0.20 seconds\n",
            "Evaluation Accuracy: 0.8842\n",
            "Evaluation ROC AUC: 0.5209\n",
            "\n",
            "Classification Report (on Evaluation Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.99      0.94     36105\n",
            "           1       0.52      0.05      0.09      4751\n",
            "\n",
            "    accuracy                           0.88     40856\n",
            "   macro avg       0.71      0.52      0.51     40856\n",
            "weighted avg       0.85      0.88      0.84     40856\n",
            "\n",
            "--------------------------------------------------\n",
            "--- Training Logistic Regression (Full) on 163421 samples... ---\n",
            "Training Time: 1.13 seconds\n",
            "Evaluation Accuracy: 0.8843\n",
            "Evaluation ROC AUC: 0.5204\n",
            "\n",
            "Classification Report (on Evaluation Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.99      0.94     36105\n",
            "           1       0.53      0.05      0.09      4751\n",
            "\n",
            "    accuracy                           0.88     40856\n",
            "   macro avg       0.71      0.52      0.51     40856\n",
            "weighted avg       0.85      0.88      0.84     40856\n",
            "\n",
            "--------------------------------------------------\n",
            "Predicting with Logistic Regression (Full) on Test Data...\n",
            "Generated submission file: submission_logistic_regression.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting and Testing Logistic Regression"
      ],
      "metadata": {
        "id": "S9aa5lGldIDr"
      },
      "id": "S9aa5lGldIDr"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- C. Prediction and Submission ---\n",
        "print(\"Predicting with Logistic Regression (Full) on Test Data...\")\n",
        "y_pred_log_reg = final_log_reg.predict(X_submit)\n",
        "\n",
        "# Create and save the submission DataFrame\n",
        "submission_df_log_reg = pd.DataFrame({\n",
        "    'ProfileID': profile_ids,\n",
        "    'RiskFlag': y_pred_log_reg\n",
        "})\n",
        "submission_filename_log_reg = 'submission_logistic_regression.csv'\n",
        "submission_df_log_reg.to_csv(submission_filename_log_reg, index=False)\n",
        "print(f\"Generated submission file: {submission_filename_log_reg}\")"
      ],
      "metadata": {
        "id": "qbbMPXhpdOft"
      },
      "id": "qbbMPXhpdOft",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}