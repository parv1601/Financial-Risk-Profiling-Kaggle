{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing and Loading data"
      ],
      "metadata": {
        "id": "hfjKxpMkXOvR"
      },
      "id": "hfjKxpMkXOvR"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "import warnings\n",
        "\n",
        "# Suppress ConvergenceWarning from LinearSVC for cleaner output\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "# --- 1. Load Data and Prepare X and y (Training) ---\n",
        "df_train = pd.read_csv(\"train_processed_parv.csv\")\n",
        "bool_cols_train = df_train.select_dtypes(include='bool').columns\n",
        "df_train[bool_cols_train] = df_train[bool_cols_train].astype(int)\n",
        "\n",
        "X = df_train.drop(columns=['ProfileID', 'RiskFlag'])\n",
        "y = df_train['RiskFlag']\n",
        "\n",
        "# Split for full training (80%) and evaluation (20%)\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Create the 20% Training Sample (25% of X_train_full = 20% of original data)\n",
        "X_train_20pct, X_temp, y_train_20pct, y_temp = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=0.75, random_state=42, stratify=y_train_full\n",
        ")\n",
        "\n",
        "input_dim = X_train_full.shape[1]\n",
        "\n",
        "print(f\"Total Features: {input_dim}\")\n",
        "print(f\"20% Training Sample Size: {len(X_train_20pct)}\")\n",
        "print(f\"Full Training Set Size: {len(X_train_full)}\")\n",
        "print(f\"Evaluation Test Set Size: {len(X_test)}\\n\")\n",
        "\n",
        "# --- 2. Load and Prepare X for Submission (Competition Test Data) ---\n",
        "df_test = pd.read_csv(\"test_processed_parv.csv\")\n",
        "bool_cols_test = df_test.select_dtypes(include='bool').columns\n",
        "df_test[bool_cols_test] = df_test[bool_cols_test].astype(int)\n",
        "\n",
        "# X_submit is the actual competition test data to predict\n",
        "X_submit = df_test.drop(columns=['ProfileID'])\n",
        "profile_ids = df_test['ProfileID']\n",
        "print(f\"Submission Test Set Size: {len(X_submit)}\\n\")\n",
        "\n",
        "\n",
        "# --- 3. Define Common Functions ---\n",
        "\n",
        "def evaluate_model(model_name, model, X_train, y_train, X_eval, y_eval, is_ann=False):\n",
        "    \"\"\"Trains, predicts, and reports metrics for a given model.\"\"\"\n",
        "    print(f\"--- Training {model_name} on {len(X_train)} samples... ---\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    if is_ann:\n",
        "        model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "    print(f\"Training Time: {training_time:.2f} seconds\")\n",
        "\n",
        "    # Predict on the hold-out evaluation set\n",
        "    if is_ann:\n",
        "        y_pred_proba = model.predict(X_eval, verbose=0)\n",
        "        y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
        "    else:\n",
        "        y_pred = model.predict(X_eval)\n",
        "\n",
        "    accuracy = accuracy_score(y_eval, y_pred)\n",
        "    auc = roc_auc_score(y_eval, y_pred)\n",
        "\n",
        "    print(f\"Evaluation Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Evaluation ROC AUC: {auc:.4f}\")\n",
        "    print(\"\\nClassification Report (on Evaluation Set):\")\n",
        "    print(classification_report(y_eval, y_pred, zero_division=0))\n",
        "    print(\"-\" * 50)\n",
        "    return model # Return the trained model\n",
        "\n",
        "def create_ann_model(input_dim):\n",
        "    \"\"\"Creates a basic ANN model for binary classification.\"\"\"\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_shape=(input_dim,)),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jzk9V2FKO8O_",
        "outputId": "30da9dd2-d595-4819-992b-46ce66ee6063"
      },
      "id": "Jzk9V2FKO8O_",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Features: 26\n",
            "20% Training Sample Size: 40855\n",
            "Full Training Set Size: 163421\n",
            "Evaluation Test Set Size: 40856\n",
            "\n",
            "Submission Test Set Size: 51070\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Common Functions and Neural Networks"
      ],
      "metadata": {
        "id": "bT1GtcmTO-wk"
      },
      "id": "bT1GtcmTO-wk"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Define Common Functions ---\n",
        "\n",
        "def evaluate_model(model_name, model, X_train, y_train, X_eval, y_eval, is_ann=False):\n",
        "    \"\"\"Trains, predicts, and reports metrics for a given model.\"\"\"\n",
        "    print(f\"--- Training {model_name} on {len(X_train)} samples... ---\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    if is_ann:\n",
        "        model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "    print(f\"Training Time: {training_time:.2f} seconds\")\n",
        "\n",
        "    # Predict on the hold-out evaluation set\n",
        "    if is_ann:\n",
        "        y_pred_proba = model.predict(X_eval, verbose=0)\n",
        "        y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
        "    else:\n",
        "        y_pred = model.predict(X_eval)\n",
        "\n",
        "    accuracy = accuracy_score(y_eval, y_pred)\n",
        "    auc = roc_auc_score(y_eval, y_pred)\n",
        "\n",
        "    print(f\"Evaluation Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Evaluation ROC AUC: {auc:.4f}\")\n",
        "    print(\"\\nClassification Report (on Evaluation Set):\")\n",
        "    print(classification_report(y_eval, y_pred, zero_division=0))\n",
        "    print(\"-\" * 50)\n",
        "    return model # Return the trained model\n",
        "\n",
        "def create_ann_model(input_dim):\n",
        "    \"\"\"Creates a basic ANN model for binary classification.\"\"\"\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_shape=(input_dim,)),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "wTVkAcWnPChr"
      },
      "id": "wTVkAcWnPChr",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear SVM"
      ],
      "metadata": {
        "id": "CjaWAVcQPQMX"
      },
      "id": "CjaWAVcQPQMX"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- A. Linear SVM (Training on 20% Sample) ---\n",
        "linear_svm_20pct = LinearSVC(random_state=42, dual=True, max_iter=10000)\n",
        "evaluate_model(\"Linear SVM (20%)\", linear_svm_20pct,\n",
        "               X_train_20pct, y_train_20pct, X_test, y_test)\n",
        "\n",
        "# --- B. Linear SVM (Training on Full Dataset) ---\n",
        "final_linear_svm = LinearSVC(random_state=42, dual=True, max_iter=10000)\n",
        "final_linear_svm = evaluate_model(\"Linear SVM (Full)\", final_linear_svm,\n",
        "                                  X_train_full, y_train_full, X_test, y_test)\n",
        "\n",
        "\n",
        "# --- C. Prediction and Submission ---\n",
        "print(\"Predicting with Linear SVM (Full) on Test Data...\")\n",
        "y_pred_linear = final_linear_svm.predict(X_submit)\n",
        "\n",
        "# Create and save the submission DataFrame\n",
        "submission_df_linear = pd.DataFrame({\n",
        "    'ProfileID': profile_ids,\n",
        "    'RiskFlag': y_pred_linear\n",
        "})\n",
        "submission_filename_linear = 'submission_linear_svm.csv'\n",
        "submission_df_linear.to_csv(submission_filename_linear, index=False)\n",
        "print(f\"Generated submission file: {submission_filename_linear}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPRZFSeNPR_F",
        "outputId": "f1efdd3b-29ef-49d6-b19c-60fd7006a5d0"
      },
      "id": "bPRZFSeNPR_F",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Training Linear SVM (20%) on 40855 samples... ---\n",
            "Training Time: 7.26 seconds\n",
            "Evaluation Accuracy: 0.8837\n",
            "Evaluation ROC AUC: 0.5002\n",
            "\n",
            "Classification Report (on Evaluation Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.94     36105\n",
            "           1       0.50      0.00      0.00      4751\n",
            "\n",
            "    accuracy                           0.88     40856\n",
            "   macro avg       0.69      0.50      0.47     40856\n",
            "weighted avg       0.84      0.88      0.83     40856\n",
            "\n",
            "--------------------------------------------------\n",
            "--- Training Linear SVM (Full) on 163421 samples... ---\n",
            "Training Time: 69.59 seconds\n",
            "Evaluation Accuracy: 0.8837\n",
            "Evaluation ROC AUC: 0.5002\n",
            "\n",
            "Classification Report (on Evaluation Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.94     36105\n",
            "           1       0.67      0.00      0.00      4751\n",
            "\n",
            "    accuracy                           0.88     40856\n",
            "   macro avg       0.78      0.50      0.47     40856\n",
            "weighted avg       0.86      0.88      0.83     40856\n",
            "\n",
            "--------------------------------------------------\n",
            "Predicting with Linear SVM (Full) on Test Data...\n",
            "Generated submission file: submission_linear_svm.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kernalized SVM"
      ],
      "metadata": {
        "id": "MrCAv7LSPVFU"
      },
      "id": "MrCAv7LSPVFU"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- A. Kernelized SVM (RBF) (Training on 20% Sample) ---\n",
        "# NOW TRAINING ON THE ENTIRE 20% SAMPLE (X_train_20pct)\n",
        "rbf_svm_20pct = SVC(kernel='rbf', gamma='scale', random_state=42)\n",
        "rbf_svm_20pct = evaluate_model(\"Kernelized SVM (RBF) (20% full sample)\", rbf_svm_20pct,\n",
        "               X_train_20pct, y_train_20pct, X_test, y_test)\n",
        "\n",
        "\n",
        "# --- B. Kernelized SVM (RBF) (Training on Full Dataset) ---\n",
        "# NOW TRAINING ON THE ENTIRE FULL TRAINING DATASET (X_train_full)\n",
        "final_rbf_svm = SVC(kernel='rbf', gamma='scale', random_state=42)\n",
        "final_rbf_svm = evaluate_model(\"Kernelized SVM (RBF) (Full Dataset)\", final_rbf_svm,\n",
        "                               X_train_full, y_train_full, X_test, y_test)\n",
        "\n",
        "\n",
        "# --- C. Prediction and Submission ---\n",
        "print(\"Predicting with Kernelized SVM (Full Dataset) on Test Data...\")\n",
        "y_pred_rbf = final_rbf_svm.predict(X_submit)\n",
        "\n",
        "# Create and save the submission DataFrame\n",
        "submission_df_rbf = pd.DataFrame({\n",
        "    'ProfileID': profile_ids,\n",
        "    'RiskFlag': y_pred_rbf\n",
        "})\n",
        "submission_filename_rbf = 'submission_kernelized_svm.csv'\n",
        "submission_df_rbf.to_csv(submission_filename_rbf, index=False)\n",
        "print(f\"Generated submission file: {submission_filename_rbf}\")"
      ],
      "metadata": {
        "id": "wJlAIvbqPZG5"
      },
      "id": "wJlAIvbqPZG5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP (Neural Networks)"
      ],
      "metadata": {
        "id": "a0zXA3dLPeuF"
      },
      "id": "a0zXA3dLPeuF"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- A. ANN (Training on 20% Sample) ---\n",
        "ann_model_20pct = create_ann_model(input_dim)\n",
        "evaluate_model(\"ANN (20%)\", ann_model_20pct,\n",
        "               X_train_20pct, y_train_20pct, X_test, y_test, is_ann=True)\n",
        "\n",
        "\n",
        "# --- B. ANN (Training on Full Dataset) ---\n",
        "final_ann_model = create_ann_model(input_dim)\n",
        "final_ann_model = evaluate_model(\"ANN (Full)\", final_ann_model,\n",
        "                                 X_train_full, y_train_full, X_test, y_test, is_ann=True)\n",
        "\n",
        "\n",
        "# --- C. Prediction and Submission ---\n",
        "print(\"Predicting with ANN (Full) on Test Data...\")\n",
        "# Predict probabilities\n",
        "y_pred_proba_ann = final_ann_model.predict(X_submit, verbose=0)\n",
        "# Convert probabilities to binary predictions (0 or 1)\n",
        "y_pred_ann = (y_pred_proba_ann > 0.5).astype(int).flatten()\n",
        "\n",
        "# Create and save the submission DataFrame\n",
        "submission_df_ann = pd.DataFrame({\n",
        "    'ProfileID': profile_ids,\n",
        "    'RiskFlag': y_pred_ann\n",
        "})\n",
        "submission_filename_ann = 'submission_mlp.csv'\n",
        "submission_df_ann.to_csv(submission_filename_ann, index=False)\n",
        "print(f\"Generated submission file: {submission_filename_ann}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--iKzZ1-PhD7",
        "outputId": "033319bc-9e4c-491b-a727-4d62b5a3cacc"
      },
      "id": "--iKzZ1-PhD7",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Training ANN (20%) on 40855 samples... ---\n",
            "Training Time: 26.20 seconds\n",
            "Evaluation Accuracy: 0.8849\n",
            "Evaluation ROC AUC: 0.5230\n",
            "\n",
            "Classification Report (on Evaluation Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.99      0.94     36105\n",
            "           1       0.55      0.05      0.09      4751\n",
            "\n",
            "    accuracy                           0.88     40856\n",
            "   macro avg       0.72      0.52      0.52     40856\n",
            "weighted avg       0.85      0.88      0.84     40856\n",
            "\n",
            "--------------------------------------------------\n",
            "--- Training ANN (Full) on 163421 samples... ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time: 104.19 seconds\n",
            "Evaluation Accuracy: 0.8850\n",
            "Evaluation ROC AUC: 0.5276\n",
            "\n",
            "Classification Report (on Evaluation Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.99      0.94     36105\n",
            "           1       0.55      0.06      0.11      4751\n",
            "\n",
            "    accuracy                           0.89     40856\n",
            "   macro avg       0.72      0.53      0.52     40856\n",
            "weighted avg       0.85      0.89      0.84     40856\n",
            "\n",
            "--------------------------------------------------\n",
            "Predicting with ANN (Full) on Test Data...\n",
            "Generated submission file: submission_ann.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "gg5gtCMDWYgQ"
      },
      "id": "gg5gtCMDWYgQ"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# --- A. Logistic Regression (Training on 20% Sample) ---\n",
        "# Use max_iter=1000 for convergence on large datasets\n",
        "log_reg_20pct = LogisticRegression(random_state=42, solver='liblinear', max_iter=1000)\n",
        "evaluate_model(\"Logistic Regression (20%)\", log_reg_20pct,\n",
        "               X_train_20pct, y_train_20pct, X_test, y_test)\n",
        "\n",
        "# --- B. Logistic Regression (Training on Full Dataset) ---\n",
        "final_log_reg = LogisticRegression(random_state=42, solver='liblinear', max_iter=1000)\n",
        "final_log_reg = evaluate_model(\"Logistic Regression (Full)\", final_log_reg,\n",
        "                               X_train_full, y_train_full, X_test, y_test)\n",
        "\n",
        "\n",
        "# --- C. Prediction and Submission ---\n",
        "print(\"Predicting with Logistic Regression (Full) on Test Data...\")\n",
        "y_pred_log_reg = final_log_reg.predict(X_submit)\n",
        "\n",
        "# Create and save the submission DataFrame\n",
        "submission_df_log_reg = pd.DataFrame({\n",
        "    'ProfileID': profile_ids,\n",
        "    'RiskFlag': y_pred_log_reg\n",
        "})\n",
        "submission_filename_log_reg = 'submission_logistic_regression.csv'\n",
        "submission_df_log_reg.to_csv(submission_filename_log_reg, index=False)\n",
        "print(f\"Generated submission file: {submission_filename_log_reg}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cr0lSYyNWbEd",
        "outputId": "3ce046b1-bab6-49a9-dcc2-c8f4e2933335"
      },
      "id": "cr0lSYyNWbEd",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Training Logistic Regression (20%) on 40855 samples... ---\n",
            "Training Time: 0.20 seconds\n",
            "Evaluation Accuracy: 0.8842\n",
            "Evaluation ROC AUC: 0.5209\n",
            "\n",
            "Classification Report (on Evaluation Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.99      0.94     36105\n",
            "           1       0.52      0.05      0.09      4751\n",
            "\n",
            "    accuracy                           0.88     40856\n",
            "   macro avg       0.71      0.52      0.51     40856\n",
            "weighted avg       0.85      0.88      0.84     40856\n",
            "\n",
            "--------------------------------------------------\n",
            "--- Training Logistic Regression (Full) on 163421 samples... ---\n",
            "Training Time: 1.13 seconds\n",
            "Evaluation Accuracy: 0.8843\n",
            "Evaluation ROC AUC: 0.5204\n",
            "\n",
            "Classification Report (on Evaluation Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.99      0.94     36105\n",
            "           1       0.53      0.05      0.09      4751\n",
            "\n",
            "    accuracy                           0.88     40856\n",
            "   macro avg       0.71      0.52      0.51     40856\n",
            "weighted avg       0.85      0.88      0.84     40856\n",
            "\n",
            "--------------------------------------------------\n",
            "Predicting with Logistic Regression (Full) on Test Data...\n",
            "Generated submission file: submission_logistic_regression.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}